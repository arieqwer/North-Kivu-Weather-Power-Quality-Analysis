{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3wgTEYNTEHroV6C/cC0da"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import xarray as xr\n",
        "import rioxarray\n",
        "import matplotlib.pyplot as plt\n",
        "from rasterstats import zonal_stats\n",
        "from datetime import datetime\n",
        "from climate_indices import compute, indices"
      ],
      "metadata": {
        "id": "C2T0g5xncATv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 1: SETUP & CONFIGURATION\n",
        "# ==========================================\n",
        "\n",
        "# Initialize Earth Engine\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except Exception:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize()\n",
        "\n",
        "START_DATE_HISTORICAL = '1981-01-01' # For SPI calibration\n",
        "END_DATE_HISTORICAL   = '2025-01-01'\n",
        "ANALYSIS_START_DATE   = '2022-05-01' # For output CSV/Plots\n",
        "ANALYSIS_END_DATE     = '2024-11-01'\n",
        "\n",
        "DATA_DIR = 'data/chirps_tif'\n",
        "PLOT_DIR_SPI1 = 'figures/spi_1'\n",
        "PLOT_DIR_SPI3 = 'figures/spi_3'\n",
        "OUTPUT_CSV = 'data/north_kivu_spi.csv'\n",
        "\n",
        "for d in [DATA_DIR, PLOT_DIR_SPI1, PLOT_DIR_SPI3, 'data']:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "ASSET_PATH = 'projects/ee-zuruyuyu/assets/airesanteNK'\n",
        "north_kivu_fc = ee.FeatureCollection(ASSET_PATH)"
      ],
      "metadata": {
        "id": "i1xUvrJlc_lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 2: DATA DOWNLOAD (EARTH ENGINE)\n",
        "# ==========================================\n",
        "\n",
        "def download_chirps_data():\n",
        "    print(\"Preparing CHIRPS monthly data...\")\n",
        "    chirps = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "                .filterDate(START_DATE_HISTORICAL, END_DATE_HISTORICAL) \\\n",
        "                .select('precipitation')\n",
        "\n",
        "    def monthly_sum(imageCollection):\n",
        "        def by_month(year):\n",
        "            months = ee.List.sequence(1, 12)\n",
        "            def sum_month(month):\n",
        "                start = ee.Date.fromYMD(year, month, 1)\n",
        "                end = start.advance(1, 'month')\n",
        "                monthly_image = imageCollection.filterDate(start, end).sum()\n",
        "                return monthly_image.set('year', year).set('month', month).set('system:time_start', start.millis())\n",
        "            return ee.List(months).map(sum_month)\n",
        "        years = ee.List.sequence(1981, 2024)\n",
        "        months_by_year = years.map(by_month).flatten()\n",
        "        return ee.ImageCollection.fromImages(months_by_year)\n",
        "\n",
        "    chirps_monthly = monthly_sum(chirps)\n",
        "    chirps_monthly = chirps_monthly.map(lambda img: img.clip(north_kivu_fc))\n",
        "\n",
        "    import geemap\n",
        "    print(\"Downloading GeoTIFFs... (This avoids Drive exports for immediate use)\")\n",
        "\n",
        "    if len(glob.glob(f'{DATA_DIR}/*.tif')) < 500:\n",
        "        geemap.download_ee_image_collection(\n",
        "            chirps_monthly,\n",
        "            out_dir=DATA_DIR,\n",
        "            scale=5000,\n",
        "            region=north_kivu_fc.geometry(),\n",
        "            crs='EPSG:4326'\n",
        "        )\n",
        "    else:\n",
        "        print(\"Files appear to be already downloaded.\")"
      ],
      "metadata": {
        "id": "HFaVT_jjdDit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 3: LOCAL PROCESSING (SPI & STATS)\n",
        "# ==========================================\n",
        "\n",
        "def load_raster_stack():\n",
        "    print(\"Loading Raster Stack...\")\n",
        "    tiff_files = sorted(glob.glob(f'{DATA_DIR}/*.tif'))\n",
        "    datasets = []\n",
        "\n",
        "    for tiff_file in tiff_files:\n",
        "        try:\n",
        "            ds = rioxarray.open_rasterio(tiff_file)\n",
        "            datasets.append(ds)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {tiff_file}: {e}\")\n",
        "\n",
        "    if not datasets:\n",
        "        raise ValueError(\"No datasets loaded.\")\n",
        "\n",
        "    monthly_precip = xr.concat(datasets, dim='time')\n",
        "    monthly_precip.name = 'precip'\n",
        "\n",
        "    dates = pd.date_range(start=START_DATE_HISTORICAL, periods=len(datasets), freq='MS')\n",
        "    monthly_precip = monthly_precip.assign_coords(time=dates)\n",
        "\n",
        "    monthly_precip = monthly_precip.where(monthly_precip != -9999, np.nan)\n",
        "\n",
        "    return monthly_precip\n",
        "\n",
        "def calculate_spi(da, scale, distribution, data_start_year, calibration_year_final):\n",
        "    print(f\"Calculating SPI-{scale}...\")\n",
        "    values = da.values\n",
        "    spi_values = np.full(values.shape, np.nan, dtype=np.float32)\n",
        "\n",
        "    rows, cols = values.shape[1], values.shape[2]\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            series = values[:, i, j]\n",
        "\n",
        "            if np.count_nonzero(~np.isnan(series)) < 30:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                spi = indices.spi(\n",
        "                    values=series,\n",
        "                    scale=scale,\n",
        "                    distribution=distribution,\n",
        "                    data_start_year=data_start_year,\n",
        "                    calibration_year_initial=data_start_year,\n",
        "                    calibration_year_final=calibration_year_final,\n",
        "                    periodicity=compute.Periodicity.monthly\n",
        "                )\n",
        "                spi_values[:, i, j] = spi\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    return xr.DataArray(\n",
        "        spi_values,\n",
        "        coords=da.coords,\n",
        "        dims=da.dims,\n",
        "        name=f'spi_{scale}'\n",
        "    )\n",
        "\n",
        "def plot_maps(da, output_folder, title_prefix, start_date, end_date):\n",
        "    print(f\"Generating plots for {title_prefix}...\")\n",
        "    subset = da.sel(time=slice(start_date, end_date))\n",
        "\n",
        "    for t in subset.time:\n",
        "        date_str = pd.to_datetime(t.values).strftime('%Y-%m-%d')\n",
        "        date_nice = pd.to_datetime(t.values).strftime('%B %Y')\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        subset.sel(time=t).plot(cmap='RdBu', vmin=-3, vmax=3)\n",
        "        plt.title(f'{title_prefix} - {date_nice}')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_folder, f'spi_{date_str}.png'))\n",
        "        plt.close()\n",
        "\n",
        "def run_zonal_stats_logic(spi1_da, spi3_da, polygons):\n",
        "    print(\"Computing Zonal Statistics...\")\n",
        "    results = []\n",
        "\n",
        "    common_times = np.intersect1d(spi1_da.time.values, spi3_da.time.values)\n",
        "    target_times = common_times[(common_times >= pd.to_datetime(ANALYSIS_START_DATE)) &\n",
        "                                (common_times <= pd.to_datetime(ANALYSIS_END_DATE))]\n",
        "\n",
        "    if spi1_da.rio.crs is None: spi1_da.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
        "    if spi3_da.rio.crs is None: spi3_da.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
        "    polygons = polygons.to_crs(spi1_da.rio.crs)\n",
        "    transform = spi1_da.rio.transform()\n",
        "\n",
        "    for t in target_times:\n",
        "        date_str = pd.to_datetime(t).strftime('%Y/%m')\n",
        "\n",
        "        arr_spi1 = spi1_da.sel(time=t).values\n",
        "        arr_spi3 = spi3_da.sel(time=t).values\n",
        "\n",
        "=        zs_1 = zonal_stats(polygons, arr_spi1, affine=transform, stats=['mean'], nodata=np.nan)\n",
        "        zs_3 = zonal_stats(polygons, arr_spi3, affine=transform, stats=['mean'], nodata=np.nan)\n",
        "\n",
        "        for i, row in polygons.iterrows():\n",
        "            name = row['name']\n",
        "            val_1 = zs_1[i]['mean']\n",
        "            val_3 = zs_3[i]['mean']\n",
        "\n",
        "            # Handle None\n",
        "            val_1 = np.nan if val_1 is None else val_1\n",
        "            val_3 = np.nan if val_3 is None else val_3\n",
        "\n",
        "            results.append({\n",
        "                'catchment area name': name,\n",
        "                'month and year': date_str,\n",
        "                'SPI-1 value': val_1,\n",
        "                'drought-1': 1 if val_1 < -1.5 else 0,\n",
        "                'wet-1': 1 if val_1 > 1.5 else 0,\n",
        "                'SPI-3 value': val_3,\n",
        "                'drought-3': 1 if val_3 < -1.5 else 0,\n",
        "                'wet-3': 1 if val_3 > 1.5 else 0\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "e7QdKr-ac9BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# MAIN EXECUTION\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    download_chirps_data()\n",
        "\n",
        "    precip_da = load_raster_stack()\n",
        "\n",
        "    spi1 = calculate_spi(precip_da, 1, indices.Distribution.gamma, 1981, 2024)\n",
        "    plot_maps(spi1, PLOT_DIR_SPI1, \"SPI 1-Month\", ANALYSIS_START_DATE, ANALYSIS_END_DATE)\n",
        "\n",
        "\n",
        "    precip_rolling = precip_da.rolling(time=3, center=False).sum().dropna(dim='time', how='all')\n",
        "    spi3 = calculate_spi(precip_rolling, 3, indices.Distribution.gamma, 1981, 2024)\n",
        "    plot_maps(spi3, PLOT_DIR_SPI3, \"SPI 3-Month\", ANALYSIS_START_DATE, ANALYSIS_END_DATE)\n",
        "\n",
        "\n",
        "    try:\n",
        "        import geemap\n",
        "        gdf = geemap.ee_to_gdf(north_kivu_fc)\n",
        "    except Exception:\n",
        "        gdf = gpd.read_file('data/airesanteNK.geojson')\n",
        "\n",
        "    final_df = run_zonal_stats_logic(spi1, spi3, gdf)\n",
        "\n",
        "    final_df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"Processing complete. Saved to {OUTPUT_CSV}\")"
      ],
      "metadata": {
        "id": "4NEIbvticyzr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
